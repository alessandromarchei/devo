expweek = 2025-mm-dd
expname = debug

# dataset
datapath = /usr/scratch/badile43/amarchei/TartanEvent/

# options
evs = True
eval = True
ddp = False
profiler = False
gpu_num = 1

# checkpoints
checkpoint =
fgraph_pickle = 
train_split = splits/tartan/old/train_split_small.txt
val_split = splits/tartan/tartan_default_val.txt        #execute every scene on this file every UPGRADE_CHECKPOINT_STEP
eval_step = 10000         #save checkpoint every N iterations. ALSO EVALUATION
tensorboard_update_step = 500         #push to tensorboard every N iterations, for visualization
first_gt_poses = 6000       #up until this step, LOSS = FLOW LOSS, after LOSS = POSE + FLOW + SCORE
checkpoint_step = 2000       #load checkpoint every N iterations, for evaluation
# preprocessing / augmentation
# TODO: introduce options
PATCHES_PER_FRAME = 96
patch_selector = "scorer"
norm = "std2"
randaug = True

# training options
batch_size = 2
iters = 18
steps = 100000  #normally 240000, it stops at that, dont care about stopping at half of sequence
lr = 0.00008
clip = 10
n_frames = 15   #15 by default
scale = 0.5     #resolution scale. 0.25 --> 160x120, 0.5 --> 320x240, 1.0 --> 640x480
square = False  #non uniform scaling, make the image square, taking the WIDTH as reference
precomputed_inputs = True  #use precomputed inputs, if False, it will compute the inputs on the fly
event_representation = "stack"

# loss
pose_weight = 10.0
flow_weight = 0.1
scores_weight = 0.05

#evaluation
###ONLY FOR EVALUATION dataset, not everyone
max_events_loaded = 500000000     #load up to N events to SAVE MEMORY, default 500M


#ARCHITECTURE
patchifier_model = "mksmall"   #original, mksmall, mkbig
ctx_feat_dim = 96
match_feat_dim = 32

#CORRELATION BLOCK
use_pyramid = False     #BASELINE : True : use both the large and small matching features stacked to form a pyramid, FALSE : use only the LARGE matching feature (1/4 resolution)